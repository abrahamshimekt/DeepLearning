{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "blA5esJtdFVP"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rurwL-W2PoIN"
      },
      "source": [
        "## Creating Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "owY9mN1oPAal"
      },
      "outputs": [],
      "source": [
        "class DenseLayer:\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = torch.matmul(inputs, self.weights) + self.biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajjr0QcUP8tA"
      },
      "source": [
        "## Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CfScOYgaorz"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6owCQofBP_iL"
      },
      "outputs": [],
      "source": [
        "class Activation_ReLU:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = torch.max(torch.tensor(0),inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_F8P2ziStfr",
        "outputId": "0c4105c8-5d68-45cc-99f3-ebd47db02da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2597, 0.0829, 0.0000],\n",
              "        [0.4555, 0.0000, 0.0563]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Activation_ReLU()\n",
        "x.forward(torch.rand(2,3)-0.5)\n",
        "x.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-apHeQahmI"
      },
      "source": [
        "### Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nlf-0k4OaffJ"
      },
      "outputs": [],
      "source": [
        "class Activation_Sigmoid:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = 1 / (1 + torch.exp(inputs*-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO3ocTzQdCoh",
        "outputId": "505096b1-014f-41e6-a5fb-a10be03337e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6082, 0.6352, 0.6232],\n",
              "        [0.6225, 0.7191, 0.7184]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Activation_Sigmoid()\n",
        "x.forward(torch.rand(2,3))\n",
        "x.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQrWxiXBax30"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wF2Lf9ESTOOU"
      },
      "outputs": [],
      "source": [
        "class Activation_Softmax:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Get unnormalized probabilities\n",
        "    exp_values = torch.exp(inputs - torch.max(inputs, axis=1, keepdim=True).values)\n",
        "    # Normalize them for each sample\n",
        "    probabilities = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "    self.output = probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q72wA_KFZUoZ",
        "outputId": "1828a060-5fe1-4b55-f376-c60eebbc8fe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3119, 0.3322, 0.3559],\n",
            "        [0.2653, 0.3398, 0.3950]])\n",
            "tensor([[1.0000],\n",
            "        [1.0000]])\n"
          ]
        }
      ],
      "source": [
        "x = Activation_Softmax()\n",
        "x.forward(torch.rand(2,3))\n",
        "print(x.output)\n",
        "print(torch.sum(x.output,axis=1,keepdim=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7usBC_5fprz"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afw7KXuNhJIy",
        "outputId": "98649b85-98d8-421e-dea7-263fbe09fed1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0150)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.clip(torch.tensor(0.015),torch.tensor(0.01),torch.tensor(0.05))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-xWPtRUefp3j"
      },
      "outputs": [],
      "source": [
        "class Loss_CategoricalCrossentropy() :\n",
        "  # Forward pass\n",
        "  def forward(self, y_pred, y_true):\n",
        "    samples = len(y_pred)\n",
        "    # Clip data to prevent division by 0\n",
        "    # Clip both sides to not drag mean towards any value\n",
        "    y_pred_clipped = torch.clip(y_pred, 1e-8, 1 - 1e-8)\n",
        "    # only if categorical labels\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "    # Mask values - only for one-hot encoded labels\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidences = torch.sum(y_pred_clipped * y_true, axis=1)\n",
        "    log_loss = -torch.log(correct_confidences)\n",
        "    data_loss = torch.mean(log_loss)\n",
        "    return data_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eNGs-5D3HcTp"
      },
      "outputs": [],
      "source": [
        "softmax_outputs = torch.tensor([[0.7, 0.1, 0.2], [0.1, 0.5, 0.4],[0.02, 0.9, 0.08]])\n",
        "class_targets = torch.tensor([[1, 0, 0], [0, 1, 0], [1, 0, 0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4JklFAfJ4HI",
        "outputId": "5e144f08-fd06-4c11-8703-3b09ffcd950d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.6539)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Loss_CategoricalCrossentropy()\n",
        "x.forward(softmax_outputs, class_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Dox6rDcVvN"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p5KqLXjIcYQK"
      },
      "outputs": [],
      "source": [
        "class Accuracy():\n",
        "  def calculate(self, y_pred, y_true):\n",
        "    predictions = torch.argmax(y_pred, axis=1)\n",
        "    if len(y_true.shape) == 2:\n",
        "      y_true = torch.argmax(y_true, axis=1)\n",
        "    accuracy = torch.mean((predictions == y_true).float())\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Szfd2FneDSZ",
        "outputId": "0b8dc680-e2c5-4582-9d1c-9a078bbcd9d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6667)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Accuracy()\n",
        "x.calculate(softmax_outputs, class_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgsrnHycPs3D"
      },
      "source": [
        "## Example 1\n",
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RQ5WMJ5YPL2W"
      },
      "outputs": [],
      "source": [
        "# Create dataset\n",
        "X = torch.rand((4,2))\n",
        "y = torch.tensor([0,1,1,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMkTvny3m2nL"
      },
      "source": [
        "## Creating model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kq3kD_Qdiv_x"
      },
      "outputs": [],
      "source": [
        "dense1 = DenseLayer(2, 4) # 2 input features and 3 output values\n",
        "activation1 = Activation_ReLU()\n",
        "dense2 = DenseLayer(4, 4)\n",
        "activation2 = Activation_ReLU()\n",
        "dense3 = DenseLayer(4, 2)\n",
        "activation3 = Activation_Softmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX-Rkz2Xm9e4"
      },
      "source": [
        "## Loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1PyNh-7jm1dF"
      },
      "outputs": [],
      "source": [
        "loss_function = Loss_CategoricalCrossentropy()\n",
        "acc = Accuracy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M9OIE3TnBcc"
      },
      "source": [
        "## Forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_uwTR_IjgDUi"
      },
      "outputs": [],
      "source": [
        "dense1.forward(X)\n",
        "activation1.forward(dense1.output)\n",
        "dense2.forward(activation1.output)\n",
        "activation2.forward(dense2.output)\n",
        "dense3.forward(activation2.output)\n",
        "activation3.forward(dense3.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnmJfx6onTOU"
      },
      "source": [
        "## Displaying results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa-g5Oo-jv6u",
        "outputId": "efef6e46-da59-4736-88fe-6599b7cf258b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]])\n",
            "loss: tensor(0.6931)\n",
            "Accuracy: tensor(0.5000)\n"
          ]
        }
      ],
      "source": [
        "print(activation3.output)\n",
        "loss = loss_function.forward(activation3.output, y)\n",
        "accuracy = acc.calculate(activation3.output,y)\n",
        "print('loss:', loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sUBHTOrUoSR"
      },
      "source": [
        "## Example 2\n",
        "### testing our model on real dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SY20DUOP3xS_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1c6k4AV439yW"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset from scikit-learn\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iaonkZUc3smg"
      },
      "outputs": [],
      "source": [
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJr3Hn4n4C6W",
        "outputId": "68c2c8f9-f291-4415-c97c-5d0006dc267f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([150, 4])\n",
            "y shape: torch.Size([150])\n",
            "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Class names: ['setosa' 'versicolor' 'virginica']\n",
            "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
            "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
            "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
            "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
            "        [5.0000, 3.6000, 1.4000, 0.2000]])\n",
            "tensor([0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Feature names:\", iris.feature_names)\n",
        "print(\"Class names:\", iris.target_names)\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-IUPALxq08Gz"
      },
      "outputs": [],
      "source": [
        "class ClassificationModel():\n",
        "\n",
        "  def __init__(self, num_of_features, num_of_class):\n",
        "    # creating the model\n",
        "    self.dense1 = DenseLayer(num_of_features,16)\n",
        "    self.activation1 = Activation_ReLU()\n",
        "    self.dense2 = DenseLayer(16, 16)\n",
        "    self.activation2 = Activation_ReLU()\n",
        "    # self.dense3 = DenseLayer(16, num_of_class)\n",
        "    self.output_layer = DenseLayer(16, num_of_class)\n",
        "    self.activation3 = Activation_Softmax()\n",
        "    # loss and accuracy\n",
        "    self.loss_function = Loss_CategoricalCrossentropy()\n",
        "    self.acc = Accuracy()\n",
        "\n",
        "  def model(self, X, y):\n",
        "    self.y = y\n",
        "    # forward pass\n",
        "    self.dense1.forward(X)\n",
        "    self.activation1.forward(self.dense1.output)\n",
        "    self.dense2.forward(self.activation1.output)\n",
        "    self.activation2.forward(self.dense2.output)\n",
        "    # self.dense3.forward(self.activation2.output)\n",
        "    self.output_layer.forward(self.activation2.output)\n",
        "    self.activation3.forward(self.output_layer.output)\n",
        "\n",
        "  def loss_and_accuracy(self):\n",
        "    self.loss = self.loss_function.forward(self.activation3.output, self.y)\n",
        "    self.accuracy = self.acc.calculate(self.activation3.output,self.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8riNec1W9L8O"
      },
      "outputs": [],
      "source": [
        "test = ClassificationModel(4, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-9kC2Jt_9V7R"
      },
      "outputs": [],
      "source": [
        "test.model(X, y)\n",
        "test.loss_and_accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FyU1kSFachW",
        "outputId": "9b506d1a-aa6d-4e20-fdab-eb0e18dc895b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: tensor(1.0986)\n",
            "Accuracy: tensor(0.3533)\n"
          ]
        }
      ],
      "source": [
        "print('loss:', test.loss)\n",
        "print(\"Accuracy:\", test.accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLdbopp80L8q"
      },
      "source": [
        "###  How can we adjust the weights and biases to decrease the loss?\n",
        "\n",
        "\n",
        "#### Option 1: randomly changing the weights, checking the loss, and repeating this until the lowest loss found.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "POhV5G77VFBd"
      },
      "outputs": [],
      "source": [
        "test_iris = ClassificationModel(4, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "makjufall6hR"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(precision=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7XGZ-zSzY_wx"
      },
      "outputs": [],
      "source": [
        "lowest_loss = torch.tensor(99999999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Jm8JQ2wYU18Y",
        "outputId": "00b6772b-cbd6-44c4-c06f-96a64c16a4aa"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5efb98d6cb16>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Perform a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtest_iris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest_iris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_iris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-52b21308e4bd>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# self.dense3.forward(self.activation2.output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-01e9127eecc2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Calculate output values from inputs, weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (150x16 and 3x3)"
          ]
        }
      ],
      "source": [
        "for iteration in range(10000):\n",
        "\n",
        "  # Perform a forward pass\n",
        "  test_iris.model(X,y)\n",
        "  test_iris.loss_and_accuracy()\n",
        "  loss = test_iris.loss\n",
        "  accuracy = test_iris.accuracy\n",
        "\n",
        "  # If loss is smaller - print and save weights and biases aside\n",
        "  if loss < lowest_loss:\n",
        "    print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
        "    best_dense1_weights = test_iris.dense1.weights\n",
        "    best_dense1_biases = test_iris.dense1.biases\n",
        "    best_dense2_weights = test_iris.dense2.weights\n",
        "    best_dense2_biases = test_iris.dense2.biases\n",
        "    # best_dense3_weights = test_iris.dense3.weights\n",
        "    # best_dense3_biases = test_iris.dense3.biases\n",
        "    best_output_layer_weights = test_iris.output_layer.weights\n",
        "    best_output_layer_biases = test_iris.output_layer.biases\n",
        "    lowest_loss = loss\n",
        "\n",
        "  # Generate a new set of weights for iteration\n",
        "  test_iris.dense1.weights = 0.01 * torch.rand(4, 16)\n",
        "  test_iris.dense1.biases = 0.01 * torch.rand(1, 16)\n",
        "  test_iris.dense2.weights = 0.01 * torch.rand(16, 16)\n",
        "  test_iris.dense2.biases = 0.01 * torch.rand(1, 16)\n",
        "  # test_iris.dense3.weights = 0.01 * torch.rand(16, 3)\n",
        "  # test_iris.dense3.biases = 0.01 * torch.rand(1, 3)\n",
        "  test_iris.output_layer.weights = 0.01 * torch.rand(16, 3)\n",
        "  test_iris.output_layer.biases = 0.01 * torch.rand(1, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRV5xCFddv30",
        "outputId": "dc1f281f-d022-492b-c70d-21e28a10f15b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: tensor(1.0986164808)\n",
            "Accuracy: tensor(0.3333333433)\n"
          ]
        }
      ],
      "source": [
        "print('loss:', test_iris.loss)\n",
        "print(\"Accuracy:\", test_iris.accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e2fFeKum7Ww"
      },
      "source": [
        "#### Option 2:  instead of setting parameters with randomly-chosen values each iteration, apply a fraction of these values to parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUwm_-d9wmHH"
      },
      "outputs": [],
      "source": [
        "test_iris = ClassificationModel(4, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovW6XSkfwuus"
      },
      "outputs": [],
      "source": [
        "lowest_loss = torch.tensor(99999999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmpdEqNlwzHj",
        "outputId": "e17f9fe2-e93b-437a-bdb5-ec4f8b9bbf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New set of weights found, iteration: 0 loss: tensor(1.0986117125) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 1 loss: tensor(1.0986101627) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 2 loss: tensor(1.0984047651) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 3 loss: tensor(1.0983660221) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 4 loss: tensor(1.0882831812) acc: tensor(0.3333333433)\n"
          ]
        }
      ],
      "source": [
        "for iteration in range(10000):\n",
        "\n",
        "  # Perform a forward pass\n",
        "  test_iris.model(X,y)\n",
        "  test_iris.loss_and_accuracy()\n",
        "  loss = test_iris.loss\n",
        "  accuracy = test_iris.accuracy\n",
        "\n",
        "  # If loss is smaller - print and save weights and biases aside\n",
        "  if loss < lowest_loss:\n",
        "    print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
        "    best_dense1_weights = test_iris.dense1.weights\n",
        "    best_dense1_biases = test_iris.dense1.biases\n",
        "    best_dense2_weights = test_iris.dense2.weights\n",
        "    best_dense2_biases = test_iris.dense2.biases\n",
        "    best_dense3_weights = test_iris.dense3.weights\n",
        "    best_dense3_biases = test_iris.dense3.biases\n",
        "    best_output_layer_weights = test_iris.output_layer.weights\n",
        "    best_output_layer_biases = test_iris.output_layer.biases\n",
        "    lowest_loss = loss\n",
        "  else:\n",
        "    test_iris.dense1.weights = best_dense1_weights\n",
        "    test_iris.dense1.biases = best_dense1_biases\n",
        "    test_iris.dense2.weights = best_dense2_weights\n",
        "    test_iris.dense2.biases = best_dense2_biases\n",
        "    test_iris.dense3.weights = best_dense3_weights\n",
        "    test_iris.dense3.biases = best_dense3_biases\n",
        "    test_iris.output_layer.weights = best_output_layer_weights\n",
        "    test_iris.output_layer.biases = best_output_layer_biases\n",
        "\n",
        "  # Generate a new set of weights for iteration\n",
        "  test_iris.dense1.weights += 0.05 * torch.rand(4, 16)\n",
        "  test_iris.dense1.biases += 0.05 * torch.rand(1, 16)\n",
        "  test_iris.dense2.weights += 0.05 * torch.rand(16, 16)\n",
        "  test_iris.dense2.biases += 0.05 * torch.rand(1, 16)\n",
        "  test_iris.dense3.weights += 0.05 * torch.rand(16, 3)\n",
        "  test_iris.dense3.biases += 0.05 * torch.rand(1, 3)\n",
        "  test_iris.output_layer.weights += 0.05 * torch.rand(3, 3)\n",
        "  test_iris.output_layer.biases += 0.05 * torch.rand(1, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4D0Dsk5EXiu"
      },
      "source": [
        "#### Option 3:  using optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FZ7Pk0gIK8v"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor([0.1, 0.5])\n",
        "y = torch.tensor([0.05, 0.95])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb5W0woZRU9_"
      },
      "outputs": [],
      "source": [
        "hidden_layer_1 = DenseLayer(2, 2)\n",
        "activation_1 = Activation_ReLU()\n",
        "output_layer = DenseLayer(2, 2)\n",
        "activation2 = Activation_Sigmoid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAoeJRRJRArn"
      },
      "outputs": [],
      "source": [
        "def forward_pass(X):\n",
        "  hidden_layer_1.forward(X)\n",
        "  activation1.forward(hidden_layer_1.output)\n",
        "  output_layer.forward(activation1.output)\n",
        "  activation2.forward(output_layer.output)\n",
        "  return activation2.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJePM510S1HH"
      },
      "outputs": [],
      "source": [
        "def back_prop(fp):\n",
        "  lr = torch.tensor(0.01)\n",
        "  back1 = (fp[0][0]-y[0])\n",
        "  back2 = (fp[0][1]-y[1])\n",
        "  \n",
        "  output_layer.weights[0][0] -= lr * back1*activation1.output[0][0]\n",
        "  output_layer.weights[0][1] -= lr * back1*activation1.output[0][1]\n",
        "  output_layer.weights[1][0] -= lr * back2*activation1.output[0][0]\n",
        "  output_layer.weights[1][1] -= lr * back2*activation1.output[0][1]\n",
        "\n",
        "  output_layer.weights[2][0] -= lr * back1*activation1.output[0][0]\n",
        "  output_layer.weights[2][1] -= lr * back1*activation1.output[0][1]\n",
        "  output_layer.weights[3][0] -= lr * back2*activation1.output[0][0]\n",
        "  output_layer.weights[3][1] -= lr * back2*activation1.output[0][1]\n",
        "\n",
        "  output_layer.biases[0][0] -= lr * back1\n",
        "  output_layer.biases[0][1] -= lr * back2\n",
        "\n",
        "  hidden_layer_1.weights[0][0] -= lr * (back1 * output_layer.weights[0][0] * X[0] + back2 * output_layer.weights[0][1] * X[0] ) if hidden_layer_1.output[0][0] > 0 else 0\n",
        "  hidden_layer_1.weights[0][1] -= lr * (back1 * output_layer.weights[0][0] * X[1] + back2 * output_layer.weights[0][1] * X[1] ) if hidden_layer_1.output[0][0] > 0 else 0\n",
        "  hidden_layer_1.weights[1][0] -= lr * (back1 * output_layer.weights[1][0] * X[0] + back2 * output_layer.weights[1][1] * X[0] ) if hidden_layer_1.output[0][1] > 0 else 0\n",
        "  hidden_layer_1.weights[1][1] -= lr * (back1 * output_layer.weights[1][0] * X[1] + back2 * output_layer.weights[1][1] * X[1] ) if hidden_layer_1.output[0][1] > 0 else 0\n",
        "\n",
        "  hidden_layer_1.weights[2][0] -= lr * (back1 * output_layer.weights[0][0] * X[0] + back2 * output_layer.weights[0][1] * X[0] ) if hidden_layer_1.output[0][0] > 0 else 0\n",
        "  hidden_layer_1.weights[2][1] -= lr * (back1 * output_layer.weights[0][0] * X[1] + back2 * output_layer.weights[0][1] * X[1] ) if hidden_layer_1.output[0][0] > 0 else 0\n",
        "  hidden_layer_1.weights[3][0] -= lr * (back1 * output_layer.weights[1][0] * X[0] + back2 * output_layer.weights[1][1] * X[0] ) if hidden_layer_1.output[0][1] > 0 else 0\n",
        "  hidden_layer_1.weights[3][1] -= lr * (back1 * output_layer.weights[1][0] * X[1] + back2 * output_layer.weights[1][1] * X[1] ) if hidden_layer_1.output[0][1] > 0 else 0\n",
        "\n",
        "\n",
        "  hidden_layer_1.biases[0][0] -= lr * (back1 * output_layer.weights[0][0] + back2 * output_layer.weights[0][1] ) if hidden_layer_1.output[0][0] > 0 else 0\n",
        "  hidden_layer_1.biases[0][1] -= lr * (back1 * output_layer.weights[1][0] + back2 * output_layer.weights[1][1] ) if hidden_layer_1.output[0][1] > 0 else 0\n",
        "\n",
        "  hidden_layer_1.biases[1][0] -= lr * (back1 * output_layer.weights[0][0] + back2 * output_layer.weights[0][1] ) if hidden_layer_1.output[0][0] > 0 else 0\n",
        "  hidden_layer_1.biases[1][1] -= lr * (back1 * output_layer.weights[1][0] + back2 * output_layer.weights[1][1] ) if hidden_layer_1.output[0][1] > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzJ7jkxaTs8D"
      },
      "outputs": [],
      "source": [
        "def error_calculation(y_true, y_pred):\n",
        "  return torch.mean(0.5*(y_true - y_pred)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNKQBlGWTgDz"
      },
      "outputs": [],
      "source": [
        "loss = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taOHtItDTR28",
        "outputId": "df5a090d-500a-409a-f3e3-67612f4ac432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial loss: tensor(0.1012488529)\n",
            "Initial prediction: tensor([[0.5000064373, 0.5000115037]])\n",
            "Final loss: tensor(9.9992852483e-05)\n",
            "Final prediction: tensor([[0.0641655624, 0.9358823299]])\n",
            "Target value: tensor([0.0500000007, 0.9499999881])\n"
          ]
        }
      ],
      "source": [
        "y_pred = forward_pass(X)\n",
        "err = error_calculation(y, y_pred)\n",
        "print(\"Initial loss:\", err)\n",
        "print(\"Initial prediction:\",y_pred)\n",
        "while err > loss:\n",
        "  back_prop(y_pred)\n",
        "  y_pred = forward_pass(X)\n",
        "  err = error_calculation(y, y_pred)\n",
        "print(\"Final loss:\", err)\n",
        "print(\"Final prediction:\",y_pred)\n",
        "print(\"Target value:\",y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
